{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# Keras API\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,AveragePooling2D,BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D://Docs//Smart India Hackathon//Medicinal Leaf Dataset//Segmented Medicinal Leaf Images//\"\n",
    "test_dir=\"D://Docs//Smart India Hackathon//Medicinal Leaf Dataset//Segmented Medicinal Leaf Images//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get count of images\n",
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples =get_files(train_dir)\n",
    "num_classes=len(glob.glob(train_dir+\"/*\"))\n",
    "test_samples=get_files(test_dir) # For testing i took only few samples from unseen data. we can evaluate using validation data which is part of train data.\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "print(test_samples,\"Test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data.\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   validation_split=0.2, # validation split 20%.\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set height and width and color of input image.\n",
    "img_width,img_height =256,256\n",
    "input_shape=(img_width,img_height,3)\n",
    "batch_size =512\n",
    "\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   batch_size=batch_size)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True, target_size=(img_width,img_height), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN building.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))          \n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = [ layer.name for layer in model.layers]\n",
    "print('layer name : ',model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = load_img(\n",
    "    \"D://Docs//Smart India Hackathon//Medicinal Leaf Dataset//Segmented Medicinal Leaf Images//Alpinia Galanga (Rasna)//AG-S-001.jpg\")\n",
    "plt.imshow(img1)\n",
    "\n",
    "# Preprocess image\n",
    "img1 = load_img(\n",
    "    \"D://Docs//Smart India Hackathon//Medicinal Leaf Dataset//Segmented Medicinal Leaf Images//Alpinia Galanga (Rasna)//AG-S-001.jpg\", target_size=(256, 256))\n",
    "img = img_to_array(img1)\n",
    "img = img / 255\n",
    "img = np.expand_dims(img, axis=0)\n",
    "# \"D:\\Docs\\Smart India Hackathon\\Medicinal Leaf Dataset\\Segmented Medicinal Leaf Images\\Alpinia Galanga (Rasna)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "conv2d_1_output = Model(inputs=model.input, outputs=model.get_layer('conv2d').output)\n",
    "max_pooling2d_1_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d').output)\n",
    "conv2d_2_output = Model(inputs=model.input,outputs=model.get_layer('conv2d_1').output)\n",
    "max_pooling2d_2_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d_1').output)\n",
    "conv2d_3_output = Model(inputs=model.input,outputs=model.get_layer('conv2d_2').output)\n",
    "max_pooling2d_3_output = Model(inputs=model.input,outputs=model.get_layer('max_pooling2d_2').output)\n",
    "flatten_1_output = Model(inputs=model.input,outputs=model.get_layer('flatten').output)\n",
    "conv2d_1_features = conv2d_1_output.predict(img)\n",
    "max_pooling2d_1_features = max_pooling2d_1_output.predict(img)\n",
    "conv2d_2_features = conv2d_2_output.predict(img)\n",
    "max_pooling2d_2_features = max_pooling2d_2_output.predict(img)\n",
    "conv2d_3_features = conv2d_3_output.predict(img)\n",
    "max_pooling2d_3_features = max_pooling2d_3_output.predict(img)\n",
    "flatten_1_features = flatten_1_output.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"D://Docs//Smart India Hackathon//all_dataset\"\n",
    "DATASET_TRAIN_DIR = os.path.join(\n",
    "    DATASET_DIR, \"/\")  # Update the directory path\n",
    "DATASET_TEST_DIR = os.path.join(\n",
    "    DATASET_DIR, \"/\")  # Update the directory path\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = len(os.listdir(DATASET_DIR))\n",
    "print (num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_1_features[0, :, :, i], cmap='viridis') # Visualizing in color mode.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_1_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_2_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also visualize in color mode.\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_2_features[0, :, :, i], cmap='viridis') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns =8 \n",
    "rows = 8\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_3_features[0, :, :, i], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,14))\n",
    "columns = 8\n",
    "rows = 8\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(max_pooling2d_3_features[0, :, :, i],cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data.\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "train = model.fit_generator(train_generator,\n",
    "                            epochs=75,\n",
    "                            steps_per_epoch=train_generator.samples // batch_size,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=validation_generator.samples // batch_size,\n",
    "                            verbose=1)\n",
    "\n",
    "\n",
    "acc = train.history['accuracy']\n",
    "val_acc = train.history['val_accuracy']\n",
    "loss = train.history['loss']\n",
    "val_loss = train.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,accuracy =model.evaluate(test_generator,verbose=1)\n",
    "print(\"Test score is {}\".format(score))\n",
    "print(\"Test accuracy is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model with optimizer, architecture, weights and training configuration.\n",
    "from keras.models import load_model\n",
    "model.save('leaf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights.\n",
    "from keras.models import load_model\n",
    "model.save_weights('leaf_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes of model trained on\n",
    "classes = train_generator.class_indices \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('leaf.h5')\n",
    "\n",
    "Classes = ['Alpinia Galanga (Rasna)',\n",
    "           'Amaranthus Viridis (Arive-Dantu)',\n",
    "           'Artocarpus Heterophyllus (Jackfruit)',\n",
    "           'Azadirachta Indica (Neem)',\n",
    "           'Basella Alba (Basale)',\n",
    "           'Brassica Juncea (Indian Mustard)',\n",
    "           'Carissa Carandas (Karanda)',\n",
    "           'Citrus Limon (Lemon)',\n",
    "           'Ficus Auriculata (Roxburgh fig)',\n",
    "           'Ficus Religiosa (Peepal Tree)',\n",
    "           'Hibiscus Rosa-sinensis',\n",
    "           'Jasminum (Jasmine)',\n",
    "           'Mangifera Indica (Mango)',\n",
    "           'Mentha (Mint)',\n",
    "           'Moringa Oleifera (Drumstick)',\n",
    "           'Muntingia Calabura (Jamaica Cherry-Gasagase)',\n",
    "           'Murraya Koenigii (Curry)',\n",
    "           'Nerium Oleander (Oleander)',\n",
    "           'Nyctanthes Arbor-tristis (Parijata)',\n",
    "           'Ocimum Tenuiflorum (Tulsi)',\n",
    "           'Piper Betle (Betel)',\n",
    "           'Plectranthus Amboinicus (Mexican Mint)',\n",
    "           'Pongamia Pinnata (Indian Beech)',\n",
    "           'Psidium Guajava (Guava)',\n",
    "           'Punica Granatum (Pomegranate)',\n",
    "           'Santalum Album (Sandalwood)',\n",
    "           'Syzygium Cumini (Jamun)',\n",
    "           'Syzygium Jambos (Rose Apple)',\n",
    "           'Tabernaemontana Divaricata (Crape Jasmine)',\n",
    "           'Trigonella Foenum-graecum (Fenugreek)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Pre-Processing test data same as train data.\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "\n",
    "def prepare(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    x = image.img_to_array(img)\n",
    "    x = x / 255\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "result = model.predict(\n",
    "    [prepare(\"C://Users//DHIRAAJ//Downloads//test1_alpinia.jpg\")])\n",
    "predicted_class = np.argmax(result)\n",
    "disease = image.load_img(\n",
    "    \"C://Users//DHIRAAJ//Downloads//test1_alpinia.jpg\", target_size=(256, 256))\n",
    "plt.imshow(disease)\n",
    "print(Classes[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "model = tf.keras.models.load_model('leaf.h5')\n",
    "\n",
    "# Convert the Keras model to a TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "open(\"output.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
